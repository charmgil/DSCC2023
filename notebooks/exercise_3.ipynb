{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxgTDkK9x3UG"
      },
      "source": [
        "#3. *k*-Nearest Neighbors\n",
        "In the third ML exercise session, we will explore the *k*-Nearest Neighbors classification algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tj1w0mUsluP"
      },
      "source": [
        "Again, we start by executing the import statements to load the necessary libraries. As a review, the library named **numpy** provides support for handling matrices and multi-dimensional arrays efficiently. It is often used with the alias `np` (aliases can be specified using `as`). The **operator** library supports using common operators as functions. Third, **matplotlib** offers various functionalities to draw line plots, scatter plots, histograms, and more. It is commonly used with the alias `plt`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHOw_fOtGRFc"
      },
      "source": [
        "â€ºimport numpy as np\n",
        "import operator\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guQnclS_Pkkr"
      },
      "source": [
        "Next, mount your Google Drive to access data files. To practice the k-NN classification algorithm, we need the following files:\n",
        "* datingTestSet.txt\n",
        "* digits.zip\n",
        "\n",
        "Data files: https://github.com/charmgil/DSCC2023\n",
        "\n",
        "All the practice code used during the camp assumes that the data files are located under datasets/DSCC/ in each individual's Google Drive.\n",
        "\n",
        "Once the files are copied, execute the following two lines of code. Then, log in with your Google account using the link that appears. After logging in, enter the pass phrase shown on the screen in Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss9J8fjto9z_"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQTeQ5NLqQ6X"
      },
      "source": [
        "### 3.1. Load a data file\n",
        "Once you have mounted Google Drive, you can execute the following function to read the file and load the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yXwVCtZqT9G"
      },
      "source": [
        "def file2matrix(filename):\n",
        "  file = open(filename)\n",
        "  n = len(file.readlines())\n",
        "\n",
        "  return_matrix = np.zeros((n, 3))\n",
        "  class_labels = []\n",
        "  file = open(filename)\n",
        "  index = 0\n",
        "  for line in file.readlines():\n",
        "    line = line.strip()\n",
        "    tokens = line.split('\\t')\n",
        "    return_matrix[index, :] = tokens[0:3]\n",
        "    class_labels.append(tokens[-1])\n",
        "    index += 1\n",
        "\n",
        "  return return_matrix, class_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQoHZNVzqXXE"
      },
      "source": [
        "Now, let us execute the following two lines of code. Make sure that the argument for `file2matrix()` corresponds to the location of the `datingTestSet.txt` file on your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8fFUHltqaDV"
      },
      "source": [
        "X, y = file2matrix('drive/MyDrive/datasets/DSCC/datingTestSet.txt')\n",
        "\n",
        "print(y)\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQdS5MpTqRE5"
      },
      "source": [
        "`datingTestSet.txt` contains some content from the data where one user of a dating site has indicated her/his preferences for 1,000 other user profiles.\n",
        "\n",
        "Through the label y, which represents the preferences, you can see the following items:\n",
        "\n",
        "* `didn't like` indicates that the user did not like the other person at all.\n",
        "* `small doses` indicates that the user liked the other person a little.\n",
        "* `large doses` indicates that the user liked the other person a lot.\n",
        "\n",
        "Each user's profile `X`, which denotes the input features, contains the following three variables:\n",
        "* First column: annual airline mileage (miles)\n",
        "* Second column: percentage of time spent on playing games annually\n",
        "* Third column: annual ice cream consumption (liters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5oAg-UOqkQX"
      },
      "source": [
        "### 3.2. Data Normalization\n",
        "\n",
        "\n",
        "Just like when dealing with the *k*-means clustering algorithm, it is essential to go through the normalization process before providing data to the *k*-NN algorithm. For this purpose, we have prepared a normalization routine consisting of three functions today: `apply_normalizer()`, `normalize_minmax()`, `and normalize_meanstd()`.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s067qiGqmVX"
      },
      "source": [
        "def apply_normalizer(dataset, offset, divisor):\n",
        "  dataset_normalized = np.zeros(dataset.shape)\n",
        "  N = dataset.shape[0]\n",
        "  dataset_normalized = dataset - np.tile(offset, (N,1))\n",
        "  dataset_normalized = dataset_normalized / np.tile(divisor, (N,1))\n",
        "\n",
        "  return dataset_normalized\n",
        "\n",
        "\n",
        "def normalize_minmax(dataset):\n",
        "  minval = dataset.min(0)\n",
        "  maxval = dataset.max(0)\n",
        "\n",
        "#   dataset_normalized = np.zeros(dataset.shape)\n",
        "#   N = dataset.shape[0]\n",
        "#   dataset_normalized = dataset - np.tile(minval, (N,1))\n",
        "#   dataset_normalized = dataset_normalized / np.tile(maxval-minval, (N,1))\n",
        "\n",
        "  dataset_normalized = apply_normalizer(dataset, minval, maxval-minval)\n",
        "\n",
        "  return dataset_normalized, minval, maxval-minval\n",
        "\n",
        "\n",
        "def normalize_meanstd(dataset):\n",
        "  meanval = dataset.mean(0)\n",
        "  stdval = dataset.std(0)\n",
        "\n",
        "#   dataset_normalized = np.zeros(dataset.shape)\n",
        "#   N = dataset.shape[0]\n",
        "#   dataset_normalized = dataset - np.tile(meanval, (N,1))\n",
        "#   dataset_normalized = dataset_normalized / np.tile(stdval, (N,1))\n",
        "\n",
        "  dataset_normalized = apply_normalizer(dataset, meanval, stdval)\n",
        "\n",
        "  return dataset_normalized, meanval, stdval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gefpBtLXqkUi"
      },
      "source": [
        "## 3.3. Implement *k*-Nearest Neighbors Algorithm (kNN)\n",
        "\n",
        "Now it is time to implement the kNN classifier. Refer to the content from the lectures and the provided code below to write your first prediction program."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_W6S9ZjrFyu"
      },
      "source": [
        "def knn(x_test, X_train, labels, k):\n",
        "\n",
        "  N_train = X_train.shape[0]\n",
        "\n",
        "  # 1: Measure the distance from x_test for all data points (rows) in X_train\n",
        "  diff_mat = np.tile(x_test, (N_train, 1)) - X_train\n",
        "  sq_diff_mat = diff_mat ** 2\n",
        "  sq_distances = sq_diff_mat.sum(axis=1)\n",
        "  distances = sq_distances ** 0.5\n",
        "\n",
        "  # 2: We find the k nearest X_train data points from x_test and construct the \"neighbor set\" I\n",
        "  sorted_dist_indicies = distances.argsort()\n",
        "\n",
        "  # 3: We make a prediction for x_test by following the majority label in the set I\n",
        "  class_count = {}\n",
        "  for i in range(k):\n",
        "    vote = labels[sorted_dist_indicies[i]]\n",
        "    class_count[vote] = class_count.get(vote, 0) + 1\n",
        "  sorted_class_count = sorted(class_count.items(), key=operator.itemgetter(1), reverse=True)\n",
        "\n",
        "  # 4: return the result\n",
        "  result = sorted_class_count[0][0]\n",
        "  # print(class_count)\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r22JOOu9qkYv"
      },
      "source": [
        "Q: What does `np.tile()` do in line 4? What does the output `diff_mat` contain?\n",
        "\n",
        "Hint: As specified earlier, `np` refers to **numpy**. The `tile` function belongs to the **numpy** library, and you can find its usage through the following link:\n",
        "https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html\n",
        "\n",
        "\n",
        "The developers of **numpy** provide documentation for all members of **numpy**, including the `tile` function. You can check it out through the following link.\n",
        "https://docs.scipy.org/doc/numpy/reference/routines.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUmRvO77qkfg"
      },
      "source": [
        "### 3.4. Test the classifier\n",
        "Let us examine the prediction accuracy on the prepared data. The test will be conducted by separating and holding out 20% of the data as **test data** and applying it to *k*NN.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMJWesjVrbtS"
      },
      "source": [
        "# Reload the dataset\n",
        "X, y = file2matrix('drive/MyDrive/datasets/DSCC/datingTestSet.txt')\n",
        "\n",
        "holdout_ratio = .2\n",
        "\n",
        "N = X.shape[0] # number of instances\n",
        "N_ts = int(N*holdout_ratio) # number of test instances\n",
        "N_tr = N - N_ts # number of training instances\n",
        "\n",
        "\n",
        "# Split the dataset\n",
        "X_tr = X[0:N_tr,:]\n",
        "y_tr = y[0:N_tr]\n",
        "\n",
        "X_ts = X[N_tr:,:]\n",
        "y_ts = y[N_tr:]\n",
        "\n",
        "# Uncomment the following lines, if you want to see the data contents\n",
        "# print(N_tr)\n",
        "# print(N_ts)\n",
        "\n",
        "# print(X_tr.shape)\n",
        "# print(X_ts.shape)\n",
        "# print(X_tr)\n",
        "# print(X_ts)\n",
        "\n",
        "# print(y_tr)\n",
        "# print(y_ts)\n",
        "\n",
        "\n",
        "# Normalize the dataset\n",
        "X_normalized_tr, off, div = normalize_minmax(X_tr)\n",
        "X_normalized_ts = apply_normalizer(X_ts, off, div)\n",
        "\n",
        "\n",
        "# Apply the classifier\n",
        "n_errors = 0\n",
        "y_pred_ts = []\n",
        "for i in range(N_ts):\n",
        "  y_pred_ts.append(knn(X_normalized_ts[i], X_normalized_tr, y_tr, 3))\n",
        "  if(y_pred_ts[i] != y_ts[i]):\n",
        "    n_errors += 1\n",
        "\n",
        "print(\"the accuracy is: %f\" % (1 - n_errors/float(N_ts)))\n",
        "print(\"the error rate is: %f\" % (n_errors/float(N_ts)))\n",
        "\n",
        "\n",
        "print(\"\\n---- (Y_true, Y_pred) pairs ----\")\n",
        "print(*list(zip(y_ts, y_pred_ts)), sep=\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHSurAxYqRMN"
      },
      "source": [
        "### 3.5. An Application\n",
        "Finally, using the loaded dataset and *k*NN, we will create a program that predicts matching scores based on user input values. That is, when you run the program, you can test it by entering answers to the questions in the input box, and you will be able to see real-time prediction results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxA9QcUErf8L"
      },
      "source": [
        "def classifyPerson():\n",
        "  resultList = ['not at all','in small doses', 'in large doses']\n",
        "\n",
        "  percentTats = float(input(\"percentage of time spent playing video games? \"))\n",
        "  ffMiles = float(input(\"frequent flier miles earned per year? \"))\n",
        "  iceCream = float(input(\"liters of ice cream consumed per year? \"))\n",
        "\n",
        "  X_hist, y_hist = file2matrix('drive/MyDrive/datasets/DSCC/datingTestSet.txt')\n",
        "\n",
        "  X_hist_normalized, off, div = normalize_minmax(X_hist)\n",
        "  X_test = np.array([ffMiles, percentTats, iceCream])\n",
        "  classifierResult = knn((X_test - off)/div, X_hist_normalized, y_hist, 3)\n",
        "  print(\"You will probably like this person: \", classifierResult)\n",
        "\n",
        "classifyPerson()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IowYuMarEmwD"
      },
      "source": [
        "<hr/>\n",
        "\n",
        "## Assignment: Analyze Results\n",
        "Here we will use the **matplotlib** library to take a quick look at the distribution of the data.\n",
        "\n",
        "First, we reload the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95WIIX2xWanz"
      },
      "source": [
        "X, y = file2matrix('drive/MyDrive/datasets/DSCC/datingTestSet.txt')\n",
        "\n",
        "y_int = []\n",
        "for i in range(N):\n",
        "  if y[i] == 'largeDoses':\n",
        "    y_int.append(3)\n",
        "  elif y[i] == 'smallDoses':\n",
        "    y_int.append(2)\n",
        "  else:\n",
        "    y_int.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eq38GXsZh8A"
      },
      "source": [
        "In the following visualization code, we use the 2nd and 3rd columns (index 1 and 2) of the input data to examine the distribution of the output labels (`y` values)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts2dbQWmEond"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "# ax.scatter(X[:,1], X[:,2])\n",
        "ax.scatter(X[:,1], X[:,2], 15*np.array(y_int), 15*np.array(y_int))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7YedSP4Z25l"
      },
      "source": [
        "In the second visualization code, we use the 1st and 2nd columns (index 0 and 1) of the input data to examine the distribution of the output labels (`y` values)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLJxtTyCXjBA"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.scatter(X[:,0], X[:,1], 15*np.array(y_int), 15*np.array(y_int))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y1ULvTnXiSV"
      },
      "source": [
        "Q: If we choose better input features for decision-making, among the 1st, 2nd, and 3rd columns, which ones would we select?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNMnqW8RrdzD"
      },
      "source": [
        "<hr/>\n",
        "\n",
        "## Take-home Assignment: Classifying hand-written digits\n",
        "\n",
        "Let us take a look at a new dataset. Before executing the code below, please download and extract the `digits.zip` file, then upload the dataset to your Google Drive.\n",
        "\n",
        "In the following example, we assume that the handwritten digits dataset (numbers `0-9` written manually) is located in `drive/MyDrive/datasets/DSCC/digits/trainingDigits` and `testDigits` directories. These directories contain text-formatted binary images. For instance, the file `trainingDigits/0_1.txt` contains the following text (**Do you see a large 0 drawn with 0s and 1s?**):\n",
        "\n",
        "```\n",
        "00000000000111110000000000000000\n",
        "00000000001111111000000000000000\n",
        "00000000011111111100000000000000\n",
        "00000000111111111110000000000000\n",
        "00000001111111111111000000000000\n",
        "00000011111110111111100000000000\n",
        "00000011111100011111110000000000\n",
        "00000011111100001111110000000000\n",
        "00000111111100000111111000000000\n",
        "00000111111100000011111000000000\n",
        "00000011111100000001111110000000\n",
        "00000111111100000000111111000000\n",
        "00000111111000000000011111000000\n",
        "00000111111000000000011111100000\n",
        "00000111111000000000011111100000\n",
        "00000111111000000000001111100000\n",
        "00000111111000000000001111100000\n",
        "00000111111000000000001111100000\n",
        "00000111111000000000001111100000\n",
        "00000111111000000000001111100000\n",
        "00000011111000000000001111100000\n",
        "00000011111100000000011111100000\n",
        "00000011111100000000111111000000\n",
        "00000001111110000000111111100000\n",
        "00000000111110000001111111000000\n",
        "00000000111110000011111110000000\n",
        "00000000111111000111111100000000\n",
        "00000000111111111111111000000000\n",
        "00000000111111111111110000000000\n",
        "00000000011111111111100000000000\n",
        "00000000001111111111000000000000\n",
        "00000000000111111110000000000000\n",
        "```\n",
        "\n",
        "Additionally, the number before the underscore (`_`) in the filename represents the label, which corresponds to numbers `0` to `9`. For example, in `0_1.txt`, the `0` before the underscore represents the label.\n",
        "\n",
        "By writing and executing the code in your Colab Notebook, you will be able to observe the process of reading and processing the text files representing the digit images one by one. Furthermore, at the end of the code execution, you can check the overall accuracy and error rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYADffPvrj0Y"
      },
      "source": [
        "import os\n",
        "\n",
        "K = 5\n",
        "\n",
        "IMG_WIDTH = 32\n",
        "IMG_HEIGHT = 32\n",
        "\n",
        "def img2vector(filename):\n",
        "  vect = np.zeros((1, 1024))\n",
        "  file = open(filename)\n",
        "  for i in range(IMG_HEIGHT):\n",
        "    line = file.readline()\n",
        "    for j in range(IMG_WIDTH):\n",
        "      vect[0, 32*i+j] = int(line[j])\n",
        "  return vect\n",
        "\n",
        "def classifyHandwrittenDigit():\n",
        "  dirname_str = 'drive/MyDrive/datasets/MLPracticum/digits/trainingDigits'\n",
        "  filelist_tr = os.listdir(dirname_str)\n",
        "  N_tr = len(filelist_tr)\n",
        "  X_tr = np.zeros((N_tr, 1024))\n",
        "  y_tr = []\n",
        "\n",
        "  # training data\n",
        "  for i in range(N_tr):\n",
        "    if i%100 == 0:\n",
        "      print('(train) Busy...', i, '/', N_tr)\n",
        "\n",
        "    filename_str = filelist_tr[i].split('.')[0]\n",
        "    label = int(filename_str.split('_')[0])\n",
        "    y_tr.append(label)\n",
        "    X_tr[i,:] = img2vector('%s/%s' % (dirname_str, filelist_tr[i]))\n",
        "\n",
        "\n",
        "  n_errors = 0\n",
        "\n",
        "  # test data\n",
        "  dirname_str = 'drive/MyDrive/datasets/MLPracticum/digits/testDigits'\n",
        "  filelist_ts = os.listdir(dirname_str)\n",
        "  N_ts = len(filelist_ts)\n",
        "  for i in range(N_ts):\n",
        "    if i%100 == 0:\n",
        "      print('(test) Busy...', i, '/', N_ts)\n",
        "\n",
        "    filename_str = filelist_ts[i].split('.')[0]\n",
        "    label = int(filename_str.split('_')[0])\n",
        "    X_ts = img2vector('%s/%s' % (dirname_str, filelist_ts[i]))\n",
        "    classifierResult = knn(X_ts, X_tr, y_tr, K)\n",
        "\n",
        "    print(type(classifierResult))\n",
        "\n",
        "    print(\"the classifier came back with: %d, the real answer is: %d\" % (classifierResult, label))\n",
        "    if (classifierResult != label): n_errors += 1.0\n",
        "  print(\"\\nthe total number of errors is: %d\" % n_errors)\n",
        "  print(\"\\nthe accuracy is: %f\" % (1 - n_errors/float(N_ts)))\n",
        "  print(\"\\nthe error rate is: %f\" % (n_errors/float(N_ts)))\n",
        "\n",
        "classifyHandwrittenDigit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXdwFQM5rd2a"
      },
      "source": [
        "### References\n",
        "* Harrington. *Machine Learning in Action*. Manning Publications Co. 2012."
      ]
    }
  ]
}